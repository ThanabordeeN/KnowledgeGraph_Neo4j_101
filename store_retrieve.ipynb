{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d049b168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-litellm\n",
      "  Downloading llama_index_llms_litellm-0.4.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting litellm<2.0.0,>=1.18.13 (from llama-index-llms-litellm)\n",
      "  Downloading litellm-1.68.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-llms-litellm)\n",
      "  Downloading llama_index_core-0.12.34.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: click in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (8.1.8)\n",
      "Collecting httpx>=0.23.0 (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.2 (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting openai<1.76.0,>=1.68.2 (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (1.1.0)\n",
      "Collecting tiktoken>=0.7.0 (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting tokenizers (from litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached rpds_py-0.24.0-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (11.2.1)\n",
      "Collecting pyyaml>=6.0.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (2.32.3)\n",
      "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached sqlalchemy-2.0.40-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tqdm<5,>=4.66.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (4.13.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (4.3.7)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<1.76.0,>=1.68.2->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<1.76.0,>=1.68.2->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<1.76.0,>=1.68.2->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<1.76.0,>=1.68.2->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<1.76.0,>=1.68.2->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (3.10)\n",
      "Requirement already satisfied: certifi in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.23.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.0.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.0.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (0.4.6)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (2.4.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached greenlet-3.2.1-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-litellm) (25.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.18.13->llama-index-llms-litellm)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Downloading llama_index_llms_litellm-0.4.1-py3-none-any.whl (10 kB)\n",
      "Downloading litellm-1.68.0-py3-none-any.whl (7.7 MB)\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 2.4/7.7 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.7/7.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.1/7.7 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.7/7.7 MB 11.6 MB/s eta 0:00:00\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading llama_index_core-0.12.34.post1-py3-none-any.whl (7.7 MB)\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 2.4/7.7 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.7/7.7 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.3/7.7 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.7/7.7 MB 11.5 MB/s eta 0:00:00\n",
      "Using cached aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
      "Using cached banks-2.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached openai-1.75.0-py3-none-any.whl (646 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.9.0-cp312-cp312-win_amd64.whl (207 kB)\n",
      "Using cached pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached rpds_py-0.24.0-cp312-cp312-win_amd64.whl (239 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached sqlalchemy-2.0.40-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached greenlet-3.2.1-cp312-cp312-win_amd64.whl (296 kB)\n",
      "Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: filetype, dirtyjson, zipp, wrapt, typing-inspection, tqdm, tenacity, sniffio, rpds-py, regex, pyyaml, pydantic-core, propcache, networkx, mypy-extensions, multidict, marshmallow, MarkupSafe, joblib, jiter, h11, griffe, greenlet, fsspec, frozenlist, filelock, distro, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, tiktoken, sqlalchemy, referencing, pydantic, nltk, jinja2, importlib-metadata, huggingface-hub, httpcore, deprecated, anyio, aiosignal, tokenizers, jsonschema-specifications, httpx, dataclasses-json, banks, aiohttp, openai, llama-index-core, jsonschema, litellm, llama-index-llms-litellm\n",
      "\n",
      "   ----------------------------------------  0/55 [filetype]\n",
      "    ---------------------------------------  1/55 [dirtyjson]\n",
      "   -- -------------------------------------  3/55 [wrapt]\n",
      "   --- ------------------------------------  5/55 [tqdm]\n",
      "   --- ------------------------------------  5/55 [tqdm]\n",
      "   ---- -----------------------------------  6/55 [tenacity]\n",
      "   ----- ----------------------------------  7/55 [sniffio]\n",
      "   ------ ---------------------------------  9/55 [regex]\n",
      "   ------- -------------------------------- 10/55 [pyyaml]\n",
      "   -------- ------------------------------- 11/55 [pydantic-core]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   --------- ------------------------------ 13/55 [networkx]\n",
      "   ---------- ----------------------------- 15/55 [multidict]\n",
      "   ----------- ---------------------------- 16/55 [marshmallow]\n",
      "   ------------- -------------------------- 18/55 [joblib]\n",
      "   ------------- -------------------------- 18/55 [joblib]\n",
      "   ------------- -------------------------- 18/55 [joblib]\n",
      "   ------------- -------------------------- 18/55 [joblib]\n",
      "   ------------- -------------------------- 18/55 [joblib]\n",
      "   -------------- ------------------------- 20/55 [h11]\n",
      "   --------------- ------------------------ 21/55 [griffe]\n",
      "   --------------- ------------------------ 21/55 [griffe]\n",
      "   --------------- ------------------------ 21/55 [griffe]\n",
      "   --------------- ------------------------ 21/55 [griffe]\n",
      "   ---------------- ----------------------- 22/55 [greenlet]\n",
      "   ---------------- ----------------------- 23/55 [fsspec]\n",
      "   ---------------- ----------------------- 23/55 [fsspec]\n",
      "   ---------------- ----------------------- 23/55 [fsspec]\n",
      "   ---------------- ----------------------- 23/55 [fsspec]\n",
      "   ----------------- ---------------------- 24/55 [frozenlist]\n",
      "   ------------------ --------------------- 26/55 [distro]\n",
      "   ------------------- -------------------- 27/55 [attrs]\n",
      "   -------------------- ------------------- 28/55 [annotated-types]\n",
      "   --------------------- ------------------ 30/55 [yarl]\n",
      "   ----------------------- ---------------- 32/55 [tiktoken]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 33/55 [sqlalchemy]\n",
      "   ------------------------ --------------- 34/55 [referencing]\n",
      "   ------------------------- -------------- 35/55 [pydantic]\n",
      "   ------------------------- -------------- 35/55 [pydantic]\n",
      "   ------------------------- -------------- 35/55 [pydantic]\n",
      "   ------------------------- -------------- 35/55 [pydantic]\n",
      "   ------------------------- -------------- 35/55 [pydantic]\n",
      "   ------------------------- -------------- 35/55 [pydantic]\n",
      "   ------------------------- -------------- 35/55 [pydantic]\n",
      "   ------------------------- -------------- 35/55 [pydantic]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 36/55 [nltk]\n",
      "   -------------------------- ------------- 37/55 [jinja2]\n",
      "   -------------------------- ------------- 37/55 [jinja2]\n",
      "   --------------------------- ------------ 38/55 [importlib-metadata]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ---------------------------- ----------- 39/55 [huggingface-hub]\n",
      "   ----------------------------- ---------- 40/55 [httpcore]\n",
      "   ----------------------------- ---------- 40/55 [httpcore]\n",
      "   ------------------------------ --------- 42/55 [anyio]\n",
      "   ------------------------------ --------- 42/55 [anyio]\n",
      "   ------------------------------ --------- 42/55 [anyio]\n",
      "   -------------------------------- ------- 44/55 [tokenizers]\n",
      "   -------------------------------- ------- 45/55 [jsonschema-specifications]\n",
      "   --------------------------------- ------ 46/55 [httpx]\n",
      "   --------------------------------- ------ 46/55 [httpx]\n",
      "   ---------------------------------- ----- 48/55 [banks]\n",
      "   ---------------------------------- ----- 48/55 [banks]\n",
      "   ----------------------------------- ---- 49/55 [aiohttp]\n",
      "   ----------------------------------- ---- 49/55 [aiohttp]\n",
      "   ----------------------------------- ---- 49/55 [aiohttp]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------ --- 50/55 [openai]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 51/55 [llama-index-core]\n",
      "   ------------------------------------- -- 52/55 [jsonschema]\n",
      "   ------------------------------------- -- 52/55 [jsonschema]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   -------------------------------------- - 53/55 [litellm]\n",
      "   ---------------------------------------  54/55 [llama-index-llms-litellm]\n",
      "   ---------------------------------------- 55/55 [llama-index-llms-litellm]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 banks-2.1.2 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 filelock-3.18.0 filetype-1.2.0 frozenlist-1.6.0 fsspec-2025.3.2 greenlet-3.2.1 griffe-1.7.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.30.2 importlib-metadata-8.7.0 jinja2-3.1.6 jiter-0.9.0 joblib-1.5.0 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 litellm-1.68.0 llama-index-core-0.12.34.post1 llama-index-llms-litellm-0.4.1 marshmallow-3.26.1 multidict-6.4.3 mypy-extensions-1.1.0 networkx-3.4.2 nltk-3.9.1 openai-1.75.0 propcache-0.3.1 pydantic-2.11.4 pydantic-core-2.33.2 pyyaml-6.0.2 referencing-0.36.2 regex-2024.11.6 rpds-py-0.24.0 sniffio-1.3.1 sqlalchemy-2.0.40 tenacity-9.1.2 tiktoken-0.9.0 tokenizers-0.21.1 tqdm-4.67.1 typing-inspect-0.9.0 typing-inspection-0.4.0 wrapt-1.17.2 yarl-1.20.0 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.34-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata (438 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.34 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index) (0.12.34.post1)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.75.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (3.11.18)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2025.3.2)\n",
      "Requirement already satisfied: httpx in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.20.0)\n",
      "Requirement already satisfied: griffe in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (4.3.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
      "Requirement already satisfied: pandas in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
      "Requirement already satisfied: sniffio in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.34->llama-index) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.34->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.34->llama-index) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (0.4.0)\n",
      "Requirement already satisfied: colorama in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13,>=0.12.34->llama-index) (0.4.6)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Using cached llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.1.8)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
      "Requirement already satisfied: joblib in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.34->llama-index) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.34->llama-index) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index) (3.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index) (25.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
      "Downloading llama_index-0.12.34-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl (14 kB)\n",
      "Using cached llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
      "Using cached pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
      "Using cached llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading llama_parse-0.6.21-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.21-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: striprtf, pypdf, llama-cloud, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "\n",
      "   -- -------------------------------------  1/16 [pypdf]\n",
      "   -- -------------------------------------  1/16 [pypdf]\n",
      "   -- -------------------------------------  1/16 [pypdf]\n",
      "   -- -------------------------------------  1/16 [pypdf]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ----- ----------------------------------  2/16 [llama-cloud]\n",
      "   ------- --------------------------------  3/16 [llama-index-readers-file]\n",
      "   ------- --------------------------------  3/16 [llama-index-readers-file]\n",
      "   ------- --------------------------------  3/16 [llama-index-readers-file]\n",
      "   -------- -------------------  5/16 [llama-index-indices-managed-llama-cloud]\n",
      "   ----------------- ----------------------  7/16 [llama-cloud-services]\n",
      "   -------------------- -------------------  8/16 [llama-parse]\n",
      "   ------------------ -------------  9/16 [llama-index-multi-modal-llms-openai]\n",
      "   ------------------------- -------------- 10/16 [llama-index-cli]\n",
      "   --------------------------- -------- 12/16 [llama-index-readers-llama-parse]\n",
      "   ------------------------------------- -- 15/16 [llama-index]\n",
      "   ---------------------------------------- 16/16 [llama-index]\n",
      "\n",
      "Successfully installed llama-cloud-0.1.19 llama-cloud-services-0.6.21 llama-index-0.12.34 llama-index-agent-openai-0.4.7 llama-index-cli-0.4.1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.38 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.21 pypdf-5.4.0 striprtf-0.0.26\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-litellm\n",
    "\n",
    "%pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00c5183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-graph-stores-neo4j\n",
      "  Downloading llama_index_graph_stores_neo4j-0.4.6-py3-none-any.whl.metadata (694 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-graph-stores-neo4j) (0.12.34.post1)\n",
      "Collecting neo4j<6.0.0,>=5.16.0 (from llama-index-graph-stores-neo4j)\n",
      "  Downloading neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.11.18)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2025.3.2)\n",
      "Requirement already satisfied: httpx in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.9.1)\n",
      "Requirement already satisfied: numpy in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.9.0)\n",
      "Requirement already satisfied: wrapt in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.20.0)\n",
      "Requirement already satisfied: griffe in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (4.3.7)\n",
      "Requirement already satisfied: pytz in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from neo4j<6.0.0,>=5.16.0->llama-index-graph-stores-neo4j) (2025.2)\n",
      "Requirement already satisfied: colorama in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.10)\n",
      "Requirement already satisfied: click in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (8.1.8)\n",
      "Requirement already satisfied: joblib in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (25.0)\n",
      "Requirement already satisfied: anyio in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\ai\\knowledgegraph\\.venv\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-graph-stores-neo4j) (3.0.2)\n",
      "Downloading llama_index_graph_stores_neo4j-0.4.6-py3-none-any.whl (17 kB)\n",
      "Downloading neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
      "Installing collected packages: neo4j, llama-index-graph-stores-neo4j\n",
      "\n",
      "   ---------------------------------------- 0/2 [neo4j]\n",
      "   ---------------------------------------- 0/2 [neo4j]\n",
      "   ---------------------------------------- 0/2 [neo4j]\n",
      "   ---------------------------------------- 0/2 [neo4j]\n",
      "   ---------------------------------------- 0/2 [neo4j]\n",
      "   ---------------------------------------- 0/2 [neo4j]\n",
      "   ---------------------------------------- 0/2 [neo4j]\n",
      "   ------------------- ------------------- 1/2 [llama-index-graph-stores-neo4j]\n",
      "   --------------------------------------- 2/2 [llama-index-graph-stores-neo4j]\n",
      "\n",
      "Successfully installed llama-index-graph-stores-neo4j-0.4.6 neo4j-5.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-graph-stores-neo4j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b7a55",
   "metadata": {},
   "source": [
    "# Knowledge Graph with Neo4j and LlamaIndex\n",
    "\n",
    "This notebook creates a knowledge graph from documents using LlamaIndex and Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3914c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.llms.litellm import LiteLLM\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990da7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c097dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LiteLLM(model=\"gemini/gemini-2.0-flash-lite\",api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "embedding = OpenAIEmbedding(model=\"text-embedding-ada-002\", api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a55f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import KnowledgeGraphIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # For local Neo4j instance if you prefer that\n",
    "username = \"neo4j\"\n",
    "password = \"password\"  # default password for local Neo4j installation\n",
    "url = \"bolt://localhost:7687\"  # standard localhost URL for Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "# Note: used to be `Neo4jPGStore`\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40306f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents= SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68a79fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|| 21/21 [00:00<00:00, 833.83it/s]\n",
      "Processing nodes:   0%|          | 0/37 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 8/8 [00:01<00:00,  4.59it/s]\n",
      "Processing nodes:   3%|         | 1/37 [00:04<02:32,  4.24s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 8/8 [00:01<00:00,  6.13it/s]\n",
      "Processing nodes:   5%|         | 2/37 [00:08<02:32,  4.36s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:01<00:00,  6.39it/s]\n",
      "Processing nodes:   8%|         | 3/37 [00:12<02:15,  3.98s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 2/2 [00:01<00:00,  1.84it/s]\n",
      "Processing nodes:  11%|         | 4/37 [00:15<02:02,  3.70s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 9/9 [00:01<00:00,  6.00it/s]\n",
      "Processing nodes:  14%|        | 5/37 [00:19<01:56,  3.64s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 10.91it/s]\n",
      "Processing nodes:  16%|        | 6/37 [00:22<01:53,  3.67s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 4/4 [00:02<00:00,  1.75it/s]\n",
      "Processing nodes:  19%|        | 7/37 [00:26<01:49,  3.66s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 9/9 [00:00<00:00,  9.01it/s]\n",
      "Processing nodes:  22%|       | 8/37 [00:29<01:38,  3.41s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 7/7 [00:01<00:00,  6.50it/s]\n",
      "Processing nodes:  24%|       | 9/37 [00:32<01:30,  3.21s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 3/3 [00:00<00:00,  3.22it/s]\n",
      "Processing nodes:  27%|       | 10/37 [00:35<01:29,  3.30s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 13.33it/s]\n",
      "Processing nodes:  30%|       | 11/37 [00:37<01:19,  3.04s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 10.95it/s]\n",
      "Processing nodes:  32%|      | 12/37 [00:40<01:13,  2.93s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 10.52it/s]\n",
      "Processing nodes:  35%|      | 13/37 [00:43<01:11,  2.99s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:01<00:00,  7.76it/s]\n",
      "Processing nodes:  38%|      | 14/37 [00:46<01:08,  2.96s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 4/4 [00:01<00:00,  3.34it/s]\n",
      "Processing nodes:  41%|      | 15/37 [00:49<01:03,  2.88s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 11.64it/s]\n",
      "Processing nodes:  43%|     | 16/37 [00:52<01:02,  2.96s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 12.94it/s]\n",
      "Processing nodes:  46%|     | 17/37 [00:55<00:57,  2.87s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:01<00:00,  8.91it/s]\n",
      "Processing nodes:  49%|     | 18/37 [00:58<00:55,  2.91s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 10.70it/s]\n",
      "Processing nodes:  51%|    | 19/37 [01:00<00:51,  2.86s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 5/5 [00:01<00:00,  3.69it/s]\n",
      "Processing nodes:  54%|    | 20/37 [01:03<00:47,  2.81s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 10.37it/s]\n",
      "Processing nodes:  57%|    | 21/37 [01:06<00:44,  2.81s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:01<00:00,  6.84it/s]\n",
      "Processing nodes:  59%|    | 22/37 [01:10<00:48,  3.23s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 8/8 [00:00<00:00,  8.46it/s]\n",
      "Processing nodes:  62%|   | 23/37 [01:13<00:44,  3.15s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 2/2 [00:00<00:00,  3.04it/s]\n",
      "Processing nodes:  65%|   | 24/37 [01:18<00:48,  3.76s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 11.11it/s]\n",
      "Processing nodes:  68%|   | 25/37 [01:21<00:40,  3.41s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 6/6 [00:00<00:00,  6.28it/s]\n",
      "Processing nodes:  70%|   | 26/37 [01:23<00:34,  3.16s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 8/8 [00:01<00:00,  6.64it/s]\n",
      "Processing nodes:  73%|  | 27/37 [01:26<00:31,  3.12s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:01<00:00,  6.58it/s]\n",
      "Processing nodes:  76%|  | 28/37 [01:30<00:27,  3.10s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 10.63it/s]\n",
      "Processing nodes:  78%|  | 29/37 [01:32<00:24,  3.02s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:01<00:00,  7.38it/s]\n",
      "Processing nodes:  81%|  | 30/37 [01:36<00:21,  3.09s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 11.71it/s]\n",
      "Processing nodes:  84%| | 31/37 [01:38<00:17,  2.96s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 12.40it/s]\n",
      "Processing nodes:  86%| | 32/37 [01:42<00:15,  3.15s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 11.35it/s]\n",
      "Processing nodes:  89%| | 33/37 [01:44<00:11,  2.97s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:00<00:00, 11.34it/s]\n",
      "Processing nodes:  92%|| 34/37 [01:48<00:09,  3.19s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:01<00:00,  7.24it/s]\n",
      "Processing nodes:  95%|| 35/37 [01:51<00:06,  3.13s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:04<00:00,  2.42it/s]\n",
      "Processing nodes:  97%|| 36/37 [01:57<00:03,  3.91s/it]\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|| 10/10 [00:01<00:00,  9.18it/s]\n",
      "Processing nodes: 100%|| 37/37 [02:00<00:00,  3.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create and build the knowledge graph index\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    property_graph_store=graph_store,\n",
    "    max_triplets_per_chunk=10,\n",
    "    show_progress=True,\n",
    "    include_embeddings=True,\n",
    "    llm=llm,\n",
    "    embed_model=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06cb77e",
   "metadata": {},
   "source": [
    "# Querying and Retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf56810",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d6970c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "('', '', '')\n",
      "['', '', '']\n",
      "['', '', '']\n",
      "(' aci', '', '')\n",
      "['', '', '']\n",
      "['', '', '']\n",
      "['', 'Is', '']\n",
      "['', '', '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cepheusn22\\AppData\\Local\\Temp\\ipykernel_17700\\767407642.py:5: RuntimeWarning: coroutine 'Dispatcher.span.<locals>.async_wrapper' was never awaited\n",
      "  nodes = retriever.retrieve(\" (2.5)  (2.6)  ACI   h/r ?\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "retriever = index.as_retriever(\n",
    "    include_text=False,  # include source text in returned nodes, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\" (2.5)  (2.6)  ACI   h/r ?\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c9ebc",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbf442a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (2.5)  (2.6)  ACI  h/r  99  (2.5)  h/r  99  (2.6)   h/r   h/r  (2.5)  (2.6) .\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(include_text=True)\n",
    "\n",
    "response = query_engine.query(\" (2.5)  (2.6)  ACI   h/r ?\")\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae798794",
   "metadata": {},
   "source": [
    "# Loading from an existing Graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59010a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    # use a different graph name to avoid collision with the previous index\n",
    ")\n",
    "index = PropertyGraphIndex.from_existing(\n",
    "    property_graph_store=graph_store,\n",
    "    llm=llm,\n",
    "    embed_model=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f0a4cd",
   "metadata": {},
   "source": [
    "## Insert New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbc5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"LlamaIndex is great!\")\n",
    "\n",
    "index.insert(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "825a892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nodes = index.as_retriever(include_text=True).retrieve(\" (2.5)  (2.6)  ACI   h/r ?\")\n",
    "\n",
    "print(nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
